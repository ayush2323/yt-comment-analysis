{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9k7Iacnf7eX",
        "outputId": "56f81539-863b-4bf4-e76b-db72e0ba3e8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (1.35.49)\n",
            "Requirement already satisfied: awscli in /usr/local/lib/python3.10/dist-packages (1.35.15)\n",
            "Requirement already satisfied: mlflow-skinny==2.17.1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.17.1)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.13.3)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.4)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.1)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.26.4)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<18,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (16.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.5.2)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.13.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.36)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.4)\n",
            "Requirement already satisfied: gunicorn<24 in /usr/local/lib/python3.10/dist-packages (from mlflow) (23.0.0)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.1->mlflow) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.1->mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.1->mlflow) (3.1.0)\n",
            "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.1->mlflow) (0.36.0)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.1->mlflow) (3.1.43)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.1->mlflow) (8.5.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.1->mlflow) (1.16.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.1->mlflow) (1.16.0)\n",
            "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.1->mlflow) (24.1)\n",
            "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.1->mlflow) (3.20.3)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.1->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.1->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.17.1->mlflow) (0.5.1)\n",
            "Requirement already satisfied: botocore<1.36.0,>=1.35.49 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.35.49)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3) (0.10.3)\n",
            "Requirement already satisfied: docutils<0.17,>=0.10 in /usr/local/lib/python3.10/dist-packages (from awscli) (0.16)\n",
            "Requirement already satisfied: colorama<0.4.7,>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from awscli) (0.4.6)\n",
            "Requirement already satisfied: rsa<4.8,>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from awscli) (4.7.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.49->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.49->boto3) (2.2.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.6)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.12.2)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.0.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (3.2.5)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.2)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from rsa<4.8,>=3.1.2->awscli) (0.6.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.10/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.1->mlflow) (2.27.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.17.1->mlflow) (4.0.11)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.17.1->mlflow) (3.20.2)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.1->mlflow) (1.2.14)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.1->mlflow) (75.1.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.37b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.17.1->mlflow) (0.37b0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.49->boto3) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.1->mlflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.1->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.1->mlflow) (2024.8.30)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.1->mlflow) (1.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.17.1->mlflow) (5.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.1->mlflow) (0.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install mlflow boto3 awscli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS4kfe8Wic9g",
        "outputId": "1a1c6484-583c-45d0-9f57-9c6b4fcb3a12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AWS Access Key ID [None]: AKIA3RYC5SSUBZMHCD5L\n",
            "AWS Secret Access Key [None]: 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\n",
            "Default region name [None]: ap-southeast-2\n",
            "Default output format [None]: \n"
          ]
        }
      ],
      "source": [
        "!aws configure"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "v0iY1MmAJ1lZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "gZ7JFvbaKE0K"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/Himanshu-1703/reddit-sentiment-analysis/refs/heads/main/data/reddit.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ybnSAn_QJ8gK",
        "outputId": "5825bcb3-1baf-4400-dec5-66490eb9afd3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       clean_comment  category\n",
              "0   family mormon have never tried explain them t...         1\n",
              "1  buddhism has very much lot compatible with chr...         1\n",
              "2  seriously don say thing first all they won get...        -1\n",
              "3  what you have learned yours and only yours wha...         0\n",
              "4  for your own benefit you may want read living ...         1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e94ac207-7b40-4775-9d96-78b8e83b3f6b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_comment</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>family mormon have never tried explain them t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>buddhism has very much lot compatible with chr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>seriously don say thing first all they won get...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what you have learned yours and only yours wha...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>for your own benefit you may want read living ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e94ac207-7b40-4775-9d96-78b8e83b3f6b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e94ac207-7b40-4775-9d96-78b8e83b3f6b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e94ac207-7b40-4775-9d96-78b8e83b3f6b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-81aeaa7c-0f10-4d48-aac0-ce089fe08772\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-81aeaa7c-0f10-4d48-aac0-ce089fe08772')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-81aeaa7c-0f10-4d48-aac0-ce089fe08772 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 37249,\n  \"fields\": [\n    {\n      \"column\": \"clean_comment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 36799,\n        \"samples\": [\n          \" course yes sir you are right should vote the current government back into power because they clearly more than one man \",\n          \"brought this with some right wingers one time they proceed link multiple articles that said these deaths were not due demonetization\",\n          \"please let know missed any information add the text part will about organizations working towards protecting privacy about the ongoing case regarding right privacy and the governments response \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": -1,\n        \"max\": 1,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          -1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "df = df[~(df['clean_comment'].str.strip() == '')]\n",
        "# Ensure necessary NLTK data is downloaded\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Je9KqfT6J_b_",
        "outputId": "29eb4cb5-2520-4fa2-c519-2e1557e1e524"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the preprocessing function\n",
        "def preprocess_comment(comment):\n",
        "    # Convert to lowercase\n",
        "    comment = comment.lower()\n",
        "\n",
        "    # Remove trailing and leading whitespaces\n",
        "    comment = comment.strip()\n",
        "\n",
        "    # Remove newline characters\n",
        "    comment = re.sub(r'\\n', ' ', comment)\n",
        "\n",
        "    # Remove non-alphanumeric characters, except punctuation\n",
        "    comment = re.sub(r'[^A-Za-z0-9\\s!?.,]', '', comment)\n",
        "\n",
        "    # Remove stopwords but retain important ones for sentiment analysis\n",
        "    stop_words = set(stopwords.words('english')) - {'not', 'but', 'however', 'no', 'yet'}\n",
        "    comment = ' '.join([word for word in comment.split() if word not in stop_words])\n",
        "\n",
        "    # Lemmatize the words\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    comment = ' '.join([lemmatizer.lemmatize(word) for word in comment.split()])\n",
        "\n",
        "    return comment"
      ],
      "metadata": {
        "id": "zEb8ze7-KHD2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the preprocessing function to the 'clean_comment' column\n",
        "df['clean_comment'] = df['clean_comment'].apply(preprocess_comment)"
      ],
      "metadata": {
        "id": "K3XDISELKL4d"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Vectorize the comments using Bag of Words (CountVectorizer)\n",
        "vectorizer = CountVectorizer(max_features=5000)  # Bag of Words model with a limit of 10000 features"
      ],
      "metadata": {
        "id": "xqijhfalKQka"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = vectorizer.fit_transform(df['clean_comment']).toarray()\n",
        "y = df['category']  # Assuming 'sentiment' is the target variable (0 or 1 for binary classification)"
      ],
      "metadata": {
        "id": "15UitrmMKSTn"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('reddit_preprocessing.csv', index=False)"
      ],
      "metadata": {
        "id": "HFmJCcu6KbO3"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv('reddit_preprocessing.csv').head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "r8qIhNpkKc9r",
        "outputId": "751f1b2d-6cd9-41a5-f3aa-44b580e41821"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       clean_comment  category\n",
              "0  family mormon never tried explain still stare ...         1\n",
              "1  buddhism much lot compatible christianity espe...         1\n",
              "2  seriously say thing first get complex explain ...        -1\n",
              "3  learned want teach different focus goal not wr...         0\n",
              "4  benefit may want read living buddha living chr...         1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e77e0de-e4aa-4154-9266-d16384d8b1c9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_comment</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>family mormon never tried explain still stare ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>buddhism much lot compatible christianity espe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>seriously say thing first get complex explain ...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>learned want teach different focus goal not wr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>benefit may want read living buddha living chr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e77e0de-e4aa-4154-9266-d16384d8b1c9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8e77e0de-e4aa-4154-9266-d16384d8b1c9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8e77e0de-e4aa-4154-9266-d16384d8b1c9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-020eb855-209c-4a12-b60b-4abf332d950a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-020eb855-209c-4a12-b60b-4abf332d950a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-020eb855-209c-4a12-b60b-4abf332d950a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"clean_comment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"buddhism much lot compatible christianity especially considering sin suffering almost thing suffering caused wanting thing want going getting thing wrong way christian would mean wanting thing coincide god wanting thing coincide but without aid jesus buddhism could also seen proof god mighty omnipotence certainly christian lucky one christ side but everyone else well many christian believe god grace salvation buddhism god way showing grace upon others would also help study thing jesus said see buddha made similar claim rich man getting heaven joke basically advocating rid material possession fact distinctly remembered jesus making someone cry someone asked achieve salvation jesus replied live like buddhist roughly translated also point buddha rarely spoke anything god theory personally knew well enough leave jesus mohamed came later remember conflict difference opinion but education fun involving enlightening easier teach something prove right like intelligent design\",\n          \"benefit may want read living buddha living christ thich nhat hanh might find subsequent discussion loved one easier able articulate parallel exist buddhism christianity surprised react negatively lost treat compassion deserved understanding although may indeed display sign hurt new path properly sharing way may alleviate fear something may perceive wrong least alien belief may help allowing long run accept although not necessarily agree decision regardless end make way\",\n          \"seriously say thing first get complex explain normal people anyway dogmatic matter say see mechante post reason decide later life move buddhism suit identity though still get keep wisdom family treat like went weird hippy phase didncha never hear end pro tip put one wall jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": -1,\n        \"max\": 1,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          -1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "VJ2rgI3fKO1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tS55A6v_ij-t"
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "# Step 2: Set up the MLflow tracking server\n",
        "mlflow.set_tracking_uri(\"http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set or create an experiment\n",
        "mlflow.set_experiment(\"Exp 1 - RandomForest Baseline\")"
      ],
      "metadata": {
        "id": "W5jDLYSbKW7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Step 2: Define and train a Random Forest baseline model using a simple train-test split\n",
        "with mlflow.start_run() as run:\n",
        "    # Log a description for the run\n",
        "    mlflow.set_tag(\"mlflow.runName\", \"RandomForest_Baseline_TrainTestSplit\")\n",
        "    mlflow.set_tag(\"experiment_type\", \"baseline\")\n",
        "    mlflow.set_tag(\"model_type\", \"RandomForestClassifier\")\n",
        "\n",
        "    # Add a description\n",
        "    mlflow.set_tag(\"description\", \"Baseline RandomForest model for sentiment analysis using Bag of Words (BoW) with a simple train-test split\")\n",
        "\n",
        "    # Log parameters for the vectorizer\n",
        "    mlflow.log_param(\"vectorizer_type\", \"CountVectorizer\")\n",
        "    mlflow.log_param(\"vectorizer_max_features\", vectorizer.max_features)\n",
        "\n",
        "    # Log Random Forest parameters\n",
        "    n_estimators = 100\n",
        "    max_depth = 15\n",
        "\n",
        "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
        "    mlflow.log_param(\"max_depth\", max_depth)\n",
        "\n",
        "    # Initialize and train the model\n",
        "    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Log metrics for each class and accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "    classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    for label, metrics in classification_rep.items():\n",
        "        if isinstance(metrics, dict):  # For precision, recall, f1-score, etc.\n",
        "            for metric, value in metrics.items():\n",
        "                mlflow.log_metric(f\"{label}_{metric}\", value)\n",
        "\n",
        "    # Confusion matrix plot\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "\n",
        "    # Save and log the confusion matrix plot\n",
        "    plt.savefig(\"confusion_matrix.png\")\n",
        "    mlflow.log_artifact(\"/content/confusion_matrix.png\")\n",
        "\n",
        "    # Log the Random Forest model\n",
        "    mlflow.sklearn.log_model(model, \"random_forest_model\")\n",
        "\n",
        "    # Optionally log the dataset itself (if it's small enough)\n",
        "    df.to_csv(\"dataset.csv\", index=False)\n",
        "    mlflow.log_artifact(\"/content/dataset.csv\")\n",
        "\n",
        "# Display final accuracy\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "qidkp_0pKfp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na-2SlRIi1vz",
        "outputId": "a216050a-401f-4196-de91-d81bb6f67b36"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='s3://at-mlflow-bucket/842501619481907262', creation_time=1730008559410, experiment_id='842501619481907262', last_update_time=1730008559410, lifecycle_stage='active', name='Exp 2 - BoW vs TfIdf', tags={}>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set or create an experiment\n",
        "mlflow.set_experiment(\"Exp 2 - BoW vs TfIdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtXH4Yaji3-3"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import mlflow.sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IUe4jNTi8jP",
        "outputId": "faedada3-6dea-4f9e-9f0b-469f3d0bb64a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(36662, 2)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('/content/reddit_preprocessing.csv').dropna(subset=['clean_comment'])\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYXLHMUs4fAt",
        "outputId": "f3100339-7c99-4ed3-db97-d3d164809716"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/10/27 07:38:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/27 07:38:21 INFO mlflow.tracking._tracking_service.client: 🏃 View run BoW_(1, 1)_RandomForest at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/842501619481907262/runs/44fb06c34dc14b2b91082cfb3ec3d71b.\n",
            "2024/10/27 07:38:21 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/842501619481907262.\n",
            "2024/10/27 07:38:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/27 07:38:53 INFO mlflow.tracking._tracking_service.client: 🏃 View run TF-IDF_(1, 1)_RandomForest at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/842501619481907262/runs/d3593edbaffb4b46aa5549b4116c80a2.\n",
            "2024/10/27 07:38:53 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/842501619481907262.\n",
            "2024/10/27 07:39:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/27 07:39:26 INFO mlflow.tracking._tracking_service.client: 🏃 View run BoW_(1, 2)_RandomForest at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/842501619481907262/runs/49d3973486344912b5760270b5b002c8.\n",
            "2024/10/27 07:39:26 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/842501619481907262.\n",
            "2024/10/27 07:39:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/27 07:39:59 INFO mlflow.tracking._tracking_service.client: 🏃 View run TF-IDF_(1, 2)_RandomForest at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/842501619481907262/runs/4d82182eab0f4fef92a9d070df40a860.\n",
            "2024/10/27 07:39:59 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/842501619481907262.\n",
            "2024/10/27 07:40:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/27 07:40:35 INFO mlflow.tracking._tracking_service.client: 🏃 View run BoW_(1, 3)_RandomForest at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/842501619481907262/runs/6f4361887d1a460f9031193026bf1798.\n",
            "2024/10/27 07:40:35 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/842501619481907262.\n",
            "2024/10/27 07:41:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/27 07:41:13 INFO mlflow.tracking._tracking_service.client: 🏃 View run TF-IDF_(1, 3)_RandomForest at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/842501619481907262/runs/154793eaa89443d685d22e0ca2187899.\n",
            "2024/10/27 07:41:13 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/842501619481907262.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Step 1: Function to run the experiment\n",
        "def run_experiment(vectorizer_type, ngram_range, vectorizer_max_features, vectorizer_name):\n",
        "    # Step 2: Vectorization\n",
        "    if vectorizer_type == \"BoW\":\n",
        "        vectorizer = CountVectorizer(ngram_range=ngram_range, max_features=vectorizer_max_features)\n",
        "    else:\n",
        "        vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=vectorizer_max_features)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category'])\n",
        "\n",
        "    X_train = vectorizer.fit_transform(X_train)\n",
        "    X_test = vectorizer.transform(X_test)\n",
        "\n",
        "    # Step 4: Define and train a Random Forest model\n",
        "    with mlflow.start_run() as run:\n",
        "        # Set tags for the experiment and run\n",
        "        mlflow.set_tag(\"mlflow.runName\", f\"{vectorizer_name}_{ngram_range}_RandomForest\")\n",
        "        mlflow.set_tag(\"experiment_type\", \"feature_engineering\")\n",
        "        mlflow.set_tag(\"model_type\", \"RandomForestClassifier\")\n",
        "\n",
        "        # Add a description\n",
        "        mlflow.set_tag(\"description\", f\"RandomForest with {vectorizer_name}, ngram_range={ngram_range}, max_features={vectorizer_max_features}\")\n",
        "\n",
        "        # Log vectorizer parameters\n",
        "        mlflow.log_param(\"vectorizer_type\", vectorizer_type)\n",
        "        mlflow.log_param(\"ngram_range\", ngram_range)\n",
        "        mlflow.log_param(\"vectorizer_max_features\", vectorizer_max_features)\n",
        "\n",
        "        # Log Random Forest parameters\n",
        "        n_estimators = 200\n",
        "        max_depth = 15\n",
        "\n",
        "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
        "        mlflow.log_param(\"max_depth\", max_depth)\n",
        "\n",
        "        # Initialize and train the model\n",
        "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Step 5: Make predictions and log metrics\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Log accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "        # Log classification report\n",
        "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
        "        for label, metrics in classification_rep.items():\n",
        "            if isinstance(metrics, dict):\n",
        "                for metric, value in metrics.items():\n",
        "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
        "\n",
        "        # Log confusion matrix\n",
        "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"Actual\")\n",
        "        plt.title(f\"Confusion Matrix: {vectorizer_name}, {ngram_range}\")\n",
        "        plt.savefig(\"confusion_matrix.png\")\n",
        "        mlflow.log_artifact(\"confusion_matrix.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # Log the model\n",
        "        mlflow.sklearn.log_model(model, f\"random_forest_model_{vectorizer_name}_{ngram_range}\")\n",
        "\n",
        "# Step 6: Run experiments for BoW and TF-IDF with different n-grams\n",
        "ngram_ranges = [(1, 1), (1, 2), (1, 3)]  # unigrams, bigrams, trigrams\n",
        "max_features = 5000  # Example max feature size\n",
        "\n",
        "for ngram_range in ngram_ranges:\n",
        "    # BoW Experiments\n",
        "    run_experiment(\"BoW\", ngram_range, max_features, vectorizer_name=\"BoW\")\n",
        "\n",
        "    # TF-IDF Experiments\n",
        "    run_experiment(\"TF-IDF\", ngram_range, max_features, vectorizer_name=\"TF-IDF\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThgF12FSB5SP",
        "outputId": "3891c6ac-3f64-44aa-fdf0-31c69c3dd5da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/10/27 08:12:13 INFO mlflow.tracking.fluent: Experiment with name 'Exp 3 - TfIdf Trigram max_features' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='s3://at-mlflow-bucket/370842401333969800', creation_time=1730016733696, experiment_id='370842401333969800', last_update_time=1730016733696, lifecycle_stage='active', name='Exp 3 - TfIdf Trigram max_features', tags={}>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set or create an experiment\n",
        "mlflow.set_experiment(\"Exp 3 - TfIdf Trigram max_features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0hUXegF6GPE",
        "outputId": "d372e785-57c9-4a75-b549-f2a7db9ace9c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/10/27 08:12:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/27 08:12:51 INFO mlflow.tracking._tracking_service.client: 🏃 View run TFIDF_Trigrams_max_features_1000 at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/370842401333969800/runs/050aa319598948c2b2932362c55cf2c5.\n",
            "2024/10/27 08:12:51 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/370842401333969800.\n",
            "2024/10/27 08:13:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/27 08:13:28 INFO mlflow.tracking._tracking_service.client: 🏃 View run TFIDF_Trigrams_max_features_2000 at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/370842401333969800/runs/dd2931795e6d468a9d9a29b77a6e2138.\n",
            "2024/10/27 08:13:28 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/370842401333969800.\n",
            "2024/10/27 08:14:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/27 08:14:06 INFO mlflow.tracking._tracking_service.client: 🏃 View run TFIDF_Trigrams_max_features_3000 at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/370842401333969800/runs/0ddf6aaad1b44711988afedb5094a013.\n",
            "2024/10/27 08:14:06 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/370842401333969800.\n",
            "2024/10/27 08:14:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/27 08:14:43 INFO mlflow.tracking._tracking_service.client: 🏃 View run TFIDF_Trigrams_max_features_4000 at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/370842401333969800/runs/c45a1d87f2c244de98025ec6391f8336.\n",
            "2024/10/27 08:14:43 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/370842401333969800.\n",
            "2024/10/27 08:15:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/27 08:15:20 INFO mlflow.tracking._tracking_service.client: 🏃 View run TFIDF_Trigrams_max_features_5000 at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/370842401333969800/runs/72bc594ac7f34a0e83ae397b10578c76.\n",
            "2024/10/27 08:15:20 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/370842401333969800.\n",
            "2024/10/27 08:15:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/27 08:15:58 INFO mlflow.tracking._tracking_service.client: 🏃 View run TFIDF_Trigrams_max_features_6000 at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/370842401333969800/runs/dde2d7368cbe42ffbfb2f82943d96d58.\n",
            "2024/10/27 08:15:58 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/370842401333969800.\n",
            "2024/10/27 08:16:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/27 08:16:36 INFO mlflow.tracking._tracking_service.client: 🏃 View run TFIDF_Trigrams_max_features_7000 at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/370842401333969800/runs/40982400afb1425db91d60b4f1701cdf.\n",
            "2024/10/27 08:16:36 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/370842401333969800.\n",
            "2024/10/27 08:17:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/27 08:17:12 INFO mlflow.tracking._tracking_service.client: 🏃 View run TFIDF_Trigrams_max_features_8000 at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/370842401333969800/runs/08fbfa66246040e3a883d34c9b0bbd94.\n",
            "2024/10/27 08:17:12 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/370842401333969800.\n",
            "2024/10/27 08:17:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/27 08:17:49 INFO mlflow.tracking._tracking_service.client: 🏃 View run TFIDF_Trigrams_max_features_9000 at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/370842401333969800/runs/62ee0dd4a9c3498ba5a59dbc2c90cbc6.\n",
            "2024/10/27 08:17:49 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/370842401333969800.\n",
            "2024/10/27 08:18:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/27 08:18:23 INFO mlflow.tracking._tracking_service.client: 🏃 View run TFIDF_Trigrams_max_features_10000 at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/370842401333969800/runs/08da54264a8841219f5a1ace547e4771.\n",
            "2024/10/27 08:18:23 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/370842401333969800.\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Function to run the experiment\n",
        "def run_experiment_tfidf_max_features(max_features):\n",
        "    ngram_range = (1, 3)  # Trigram setting\n",
        "\n",
        "    # Step 2: Vectorization using TF-IDF with varying max_features\n",
        "    vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category'])\n",
        "\n",
        "    X_train = vectorizer.fit_transform(X_train)\n",
        "    X_test = vectorizer.transform(X_test)\n",
        "\n",
        "    # Step 4: Define and train a Random Forest model\n",
        "    with mlflow.start_run() as run:\n",
        "        # Set tags for the experiment and run\n",
        "        mlflow.set_tag(\"mlflow.runName\", f\"TFIDF_Trigrams_max_features_{max_features}\")\n",
        "        mlflow.set_tag(\"experiment_type\", \"feature_engineering\")\n",
        "        mlflow.set_tag(\"model_type\", \"RandomForestClassifier\")\n",
        "\n",
        "        # Add a description\n",
        "        mlflow.set_tag(\"description\", f\"RandomForest with TF-IDF Trigrams, max_features={max_features}\")\n",
        "\n",
        "        # Log vectorizer parameters\n",
        "        mlflow.log_param(\"vectorizer_type\", \"TF-IDF\")\n",
        "        mlflow.log_param(\"ngram_range\", ngram_range)\n",
        "        mlflow.log_param(\"vectorizer_max_features\", max_features)\n",
        "\n",
        "        # Log Random Forest parameters\n",
        "        n_estimators = 200\n",
        "        max_depth = 15\n",
        "\n",
        "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
        "        mlflow.log_param(\"max_depth\", max_depth)\n",
        "\n",
        "        # Initialize and train the model\n",
        "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Step 5: Make predictions and log metrics\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Log accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "        # Log classification report\n",
        "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
        "        for label, metrics in classification_rep.items():\n",
        "            if isinstance(metrics, dict):\n",
        "                for metric, value in metrics.items():\n",
        "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
        "\n",
        "        # Log confusion matrix\n",
        "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"Actual\")\n",
        "        plt.title(f\"Confusion Matrix: TF-IDF Trigrams, max_features={max_features}\")\n",
        "        plt.savefig(\"confusion_matrix.png\")\n",
        "        mlflow.log_artifact(\"confusion_matrix.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # Log the model\n",
        "        mlflow.sklearn.log_model(model, f\"random_forest_model_tfidf_trigrams_{max_features}\")\n",
        "\n",
        "# Step 6: Test various max_features values\n",
        "max_features_values = [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
        "\n",
        "for max_features in max_features_values:\n",
        "    run_experiment_tfidf_max_features(max_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbxxjPcS_9ku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de0816e8-d907-4bf3-d720-b22c5bb8109e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/10/27 08:27:13 INFO mlflow.tracking.fluent: Experiment with name 'Exp 4 - Handling Imbalanced Data' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='s3://at-mlflow-bucket/444211338567708654', creation_time=1730017633363, experiment_id='444211338567708654', last_update_time=1730017633363, lifecycle_stage='active', name='Exp 4 - Handling Imbalanced Data', tags={}>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Set or create an experiment\n",
        "mlflow.set_experiment(\"Exp 4 - Handling Imbalanced Data\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.combine import SMOTEENN\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "5Of3qQyBFfRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Function to run the experiment\n",
        "def run_imbalanced_experiment(imbalance_method):\n",
        "    ngram_range = (1, 3)  # Trigram setting\n",
        "    max_features = 10000  # Set max_features to 1000 for TF-IDF\n",
        "\n",
        "    # Step 4: Train-test split before vectorization and resampling\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category'])\n",
        "\n",
        "    # Step 2: Vectorization using TF-IDF, fit on training data only\n",
        "    vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
        "    X_train_vec = vectorizer.fit_transform(X_train)  # Fit on training data\n",
        "    X_test_vec = vectorizer.transform(X_test)  # Transform test data\n",
        "\n",
        "    # Step 3: Handle class imbalance based on the selected method (only applied to the training set)\n",
        "    if imbalance_method == 'class_weights':\n",
        "        # Use class_weight in Random Forest\n",
        "        class_weight = 'balanced'\n",
        "    else:\n",
        "        class_weight = None  # Do not apply class_weight if using resampling\n",
        "\n",
        "        # Resampling Techniques (only apply to the training set)\n",
        "        if imbalance_method == 'oversampling':\n",
        "            smote = SMOTE(random_state=42)\n",
        "            X_train_vec, y_train = smote.fit_resample(X_train_vec, y_train)\n",
        "        elif imbalance_method == 'adasyn':\n",
        "            adasyn = ADASYN(random_state=42)\n",
        "            X_train_vec, y_train = adasyn.fit_resample(X_train_vec, y_train)\n",
        "        elif imbalance_method == 'undersampling':\n",
        "            rus = RandomUnderSampler(random_state=42)\n",
        "            X_train_vec, y_train = rus.fit_resample(X_train_vec, y_train)\n",
        "        elif imbalance_method == 'smote_enn':\n",
        "            smote_enn = SMOTEENN(random_state=42)\n",
        "            X_train_vec, y_train = smote_enn.fit_resample(X_train_vec, y_train)\n",
        "\n",
        "    # Step 5: Define and train a Random Forest model\n",
        "    with mlflow.start_run() as run:\n",
        "        # Set tags for the experiment and run\n",
        "        mlflow.set_tag(\"mlflow.runName\", f\"Imbalance_{imbalance_method}_RandomForest_TFIDF_Trigrams\")\n",
        "        mlflow.set_tag(\"experiment_type\", \"imbalance_handling\")\n",
        "        mlflow.set_tag(\"model_type\", \"RandomForestClassifier\")\n",
        "\n",
        "        # Add a description\n",
        "        mlflow.set_tag(\"description\", f\"RandomForest with TF-IDF Trigrams, imbalance handling method={imbalance_method}\")\n",
        "\n",
        "        # Log vectorizer parameters\n",
        "        mlflow.log_param(\"vectorizer_type\", \"TF-IDF\")\n",
        "        mlflow.log_param(\"ngram_range\", ngram_range)\n",
        "        mlflow.log_param(\"vectorizer_max_features\", max_features)\n",
        "\n",
        "        # Log Random Forest parameters\n",
        "        n_estimators = 200\n",
        "        max_depth = 15\n",
        "\n",
        "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
        "        mlflow.log_param(\"max_depth\", max_depth)\n",
        "        mlflow.log_param(\"imbalance_method\", imbalance_method)\n",
        "\n",
        "        # Initialize and train the model\n",
        "        model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42, class_weight=class_weight)\n",
        "        model.fit(X_train_vec, y_train)\n",
        "\n",
        "        # Step 6: Make predictions and log metrics\n",
        "        y_pred = model.predict(X_test_vec)\n",
        "\n",
        "        # Log accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "        # Log classification report\n",
        "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
        "        for label, metrics in classification_rep.items():\n",
        "            if isinstance(metrics, dict):\n",
        "                for metric, value in metrics.items():\n",
        "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
        "\n",
        "        # Log confusion matrix\n",
        "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"Actual\")\n",
        "        plt.title(f\"Confusion Matrix: TF-IDF Trigrams, Imbalance={imbalance_method}\")\n",
        "        confusion_matrix_filename = f\"confusion_matrix_{imbalance_method}.png\"\n",
        "        plt.savefig(confusion_matrix_filename)\n",
        "        mlflow.log_artifact(confusion_matrix_filename)\n",
        "        plt.close()\n",
        "\n",
        "        # Log the model\n",
        "        mlflow.sklearn.log_model(model, f\"random_forest_model_tfidf_trigrams_imbalance_{imbalance_method}\")\n",
        "\n",
        "# Step 7: Run experiments for different imbalance methods\n",
        "imbalance_methods = ['class_weights', 'oversampling', 'adasyn', 'undersampling', 'smote_enn']\n",
        "\n",
        "for method in imbalance_methods:\n",
        "    run_imbalanced_experiment(method)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnyfsLitFj3Y",
        "outputId": "d6fb81ef-1832-4a24-8500-ca8633926f97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/10/27 08:28:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/27 08:28:32 INFO mlflow.tracking._tracking_service.client: 🏃 View run Imbalance_class_weights_RandomForest_TFIDF_Trigrams at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/444211338567708654/runs/e79ad617b73a4c7c97163945a1620ef3.\n",
            "2024/10/27 08:28:32 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/444211338567708654.\n",
            "2024/10/27 08:29:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/27 08:29:17 INFO mlflow.tracking._tracking_service.client: 🏃 View run Imbalance_oversampling_RandomForest_TFIDF_Trigrams at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/444211338567708654/runs/f597522f9ef544378094f9e3dc1c38fb.\n",
            "2024/10/27 08:29:17 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/444211338567708654.\n",
            "2024/10/27 08:30:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/27 08:30:17 INFO mlflow.tracking._tracking_service.client: 🏃 View run Imbalance_adasyn_RandomForest_TFIDF_Trigrams at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/444211338567708654/runs/4b0faba2188a4d5bb1d8784b4f640c9b.\n",
            "2024/10/27 08:30:17 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/444211338567708654.\n",
            "2024/10/27 08:30:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/27 08:30:53 INFO mlflow.tracking._tracking_service.client: 🏃 View run Imbalance_undersampling_RandomForest_TFIDF_Trigrams at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/444211338567708654/runs/24aa7b0051fc4eef9923aaab45f1e25b.\n",
            "2024/10/27 08:30:53 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/444211338567708654.\n",
            "2024/10/27 08:32:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
            "2024/10/27 08:32:21 INFO mlflow.tracking._tracking_service.client: 🏃 View run Imbalance_smote_enn_RandomForest_TFIDF_Trigrams at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/444211338567708654/runs/c41c8d1535ee4a43b8b355efbf1876c6.\n",
            "2024/10/27 08:32:21 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://ec2-13-236-183-252.ap-southeast-2.compute.amazonaws.com:5000/#/experiments/444211338567708654.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna xgboost imbalanced-learn"
      ],
      "metadata": {
        "id": "7wyBIy4kFoFo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e4d499c-d76a-4bec-c7fe-060155e40818"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.1)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.4)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.13.3)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.23.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.6)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.0.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.8.2 optuna-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set or create an experiment\n",
        "mlflow.set_experiment(\"Exp 5 - ML Algos with HP Tuning\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxBqq4NoMPtY",
        "outputId": "df1fb7d0-5793-4a3b-ffdf-a4abdbed6cb1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024/10/27 08:57:46 INFO mlflow.tracking.fluent: Experiment with name 'Exp 5 - ML Algos with HP Tuning' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='s3://at-mlflow-bucket/402277135365569227', creation_time=1730019466900, experiment_id='402277135365569227', last_update_time=1730019466900, lifecycle_stage='active', name='Exp 5 - ML Algos with HP Tuning', tags={}>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYMOOr9gMe84",
        "outputId": "a34ec4da-cb31-4cb8-88af-d7bb8576e08d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Remap the class labels from [-1, 0, 1] to [2, 0, 1]\n",
        "df['category'] = df['category'].map({-1: 2, 0: 0, 1: 1})\n",
        "\n",
        "# Step 2: Remove rows where the target labels (category) are NaN\n",
        "df = df.dropna(subset=['category'])\n",
        "\n",
        "ngram_range = (1, 3)  # Trigram setting\n",
        "max_features = 10000  # Set max_features to 1000 for TF-IDF\n",
        "\n",
        "# Step 4: Train-test split before vectorization and resampling\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category'])\n",
        "\n",
        "# Step 2: Vectorization using TF-IDF, fit on training data only\n",
        "vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)  # Fit on training data\n",
        "X_test_vec = vectorizer.transform(X_test)  # Transform test data\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_vec, y_train = smote.fit_resample(X_train_vec, y_train)\n",
        "\n",
        "# Function to log results in MLflow\n",
        "def log_mlflow(model_name, model, X_train, X_test, y_train, y_test):\n",
        "    with mlflow.start_run():\n",
        "        # Log model type\n",
        "        mlflow.set_tag(\"mlflow.runName\", f\"{model_name}_SMOTE_TFIDF_Trigrams\")\n",
        "        mlflow.set_tag(\"experiment_type\", \"algorithm_comparison\")\n",
        "\n",
        "        # Log algorithm name as a parameter\n",
        "        mlflow.log_param(\"algo_name\", model_name)\n",
        "\n",
        "        # Train model\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Log accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "        # Log classification report\n",
        "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
        "        for label, metrics in classification_rep.items():\n",
        "            if isinstance(metrics, dict):\n",
        "                for metric, value in metrics.items():\n",
        "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
        "\n",
        "        # Log the model\n",
        "        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n",
        "\n",
        "\n",
        "# Step 6: Optuna objective function for XGBoost\n",
        "def objective_xgboost(trial):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
        "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
        "\n",
        "    model = XGBClassifier(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, random_state=42)\n",
        "    return accuracy_score(y_test, model.fit(X_train_vec, y_train).predict(X_test_vec))\n",
        "\n",
        "\n",
        "# Step 7: Run Optuna for XGBoost, log the best model only\n",
        "def run_optuna_experiment():\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective_xgboost, n_trials=30)\n",
        "\n",
        "    # Get the best parameters and log only the best model\n",
        "    best_params = study.best_params\n",
        "    best_model = XGBClassifier(n_estimators=best_params['n_estimators'], learning_rate=best_params['learning_rate'], max_depth=best_params['max_depth'], random_state=42)\n",
        "\n",
        "    # Log the best model with MLflow, passing the algo_name as \"xgboost\"\n",
        "    log_mlflow(\"XGBoost\", best_model, X_train_vec, X_test_vec, y_train, y_test)\n",
        "\n",
        "# Run the experiment for XGBoost\n",
        "run_optuna_experiment()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xDjD2uDMhjQ",
        "outputId": "d2467b36-bdf6-401c-e8c3-2755a538c72c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-10-27 08:58:41,776] A new study created in memory with name: no-name-55f638b5-e094-4aba-9223-47fe79b7fb8f\n",
            "[I 2024-10-27 09:12:05,762] Trial 0 finished with value: 0.6095936947954885 and parameters: {'n_estimators': 160, 'learning_rate': 0.00016134414164123816, 'max_depth': 10}. Best is trial 0 with value: 0.6095936947954885.\n",
            "[I 2024-10-27 09:27:04,636] Trial 1 finished with value: 0.5984508764777823 and parameters: {'n_estimators': 284, 'learning_rate': 0.0003520611807525588, 'max_depth': 8}. Best is trial 0 with value: 0.6095936947954885.\n",
            "[I 2024-10-27 09:33:21,041] Trial 2 finished with value: 0.5935589074602527 and parameters: {'n_estimators': 121, 'learning_rate': 0.0002706299801758845, 'max_depth': 8}. Best is trial 0 with value: 0.6095936947954885.\n",
            "[I 2024-10-27 09:38:51,187] Trial 3 finished with value: 0.6621823617339312 and parameters: {'n_estimators': 136, 'learning_rate': 0.016286932607266956, 'max_depth': 7}. Best is trial 3 with value: 0.6621823617339312.\n",
            "[I 2024-10-27 09:41:13,054] Trial 4 finished with value: 0.5763011278706346 and parameters: {'n_estimators': 159, 'learning_rate': 0.004181202001950192, 'max_depth': 4}. Best is trial 3 with value: 0.6621823617339312.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Optuna objective function for LightGBM\n",
        "def objective_lightgbm(trial):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
        "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
        "\n",
        "    model = LGBMClassifier(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, random_state=42)\n",
        "    return accuracy_score(y_test, model.fit(X_train, y_train).predict(X_test))\n",
        "\n",
        "# Step 7: Run Optuna for LightGBM, log the best model only\n",
        "def run_optuna_experiment():\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective_lightgbm, n_trials=30)\n",
        "\n",
        "    # Get the best parameters and log only the best model\n",
        "    best_params = study.best_params\n",
        "    best_model = LGBMClassifier(n_estimators=best_params['n_estimators'], learning_rate=best_params['learning_rate'], max_depth=best_params['max_depth'], random_state=42)\n",
        "\n",
        "    # Log the best model with MLflow, passing the algo_name as \"LightGBM\"\n",
        "    log_mlflow(\"LightGBM\", best_model, X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "_B8vR-zIMoXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Optuna objective function for SVM\n",
        "def objective_svm(trial):\n",
        "    C = trial.suggest_float('C', 1e-4, 10.0, log=True)\n",
        "    kernel = trial.suggest_categorical('kernel', ['linear', 'rbf', 'poly'])\n",
        "\n",
        "    model = SVC(C=C, kernel=kernel, random_state=42)\n",
        "    return accuracy_score(y_test, model.fit(X_train, y_train).predict(X_test))\n",
        "\n",
        "\n",
        "# Step 7: Run Optuna for SVM, log the best model only\n",
        "def run_optuna_experiment():\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective_svm, n_trials=30)\n",
        "\n",
        "    # Get the best parameters and log only the best model\n",
        "    best_params = study.best_params\n",
        "    best_model = SVC(C=best_params['C'], kernel=best_params['kernel'], random_state=42)\n",
        "\n",
        "    # Log the best model with MLflow, passing the algo_name as \"SVM\"\n",
        "    log_mlflow(\"SVM\", best_model, X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Run the experiment for SVM\n",
        "run_optuna_experiment()"
      ],
      "metadata": {
        "id": "BhCweNHsN__u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 6: Optuna objective function for KNN\n",
        "def objective_knn(trial):\n",
        "    n_neighbors = trial.suggest_int('n_neighbors', 3, 30)  # Tuning the number of neighbors\n",
        "    p = trial.suggest_categorical('p', [1, 2])  # Tuning the distance metric (1 for Manhattan, 2 for Euclidean)\n",
        "\n",
        "    # KNeighborsClassifier setup\n",
        "    model = KNeighborsClassifier(n_neighbors=n_neighbors, p=p)\n",
        "    return accuracy_score(y_test, model.fit(X_train, y_train).predict(X_test))\n",
        "\n",
        "\n",
        "# Step 7: Run Optuna for KNN, log the best model only\n",
        "def run_optuna_experiment():\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective_knn, n_trials=30)\n",
        "\n",
        "    # Get the best parameters and log only the best model\n",
        "    best_params = study.best_params\n",
        "    best_model = KNeighborsClassifier(n_neighbors=best_params['n_neighbors'], p=best_params['p'])\n",
        "\n",
        "    # Log the best model with MLflow, passing the algo_name as \"KNN\"\n",
        "    log_mlflow(\"KNN\", best_model, X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Run the experiment for KNN\n",
        "run_optuna_experiment()\n"
      ],
      "metadata": {
        "id": "48mmR3mFO9V-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Optuna objective function for Multinomial Naive Bayes\n",
        "def objective_mnb(trial):\n",
        "    alpha = trial.suggest_float('alpha', 1e-4, 1.0, log=True)  # Tuning the smoothing parameter\n",
        "\n",
        "    # MultinomialNB model setup\n",
        "    model = MultinomialNB(alpha=alpha)\n",
        "    return accuracy_score(y_test, model.fit(X_train, y_train).predict(X_test))\n",
        "\n",
        "\n",
        "# Step 7: Run Optuna for Multinomial Naive Bayes, log the best model only\n",
        "def run_optuna_experiment():\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective_mnb, n_trials=30)\n",
        "\n",
        "    # Get the best parameters and log only the best model\n",
        "    best_params = study.best_params\n",
        "    best_model = MultinomialNB(alpha=best_params['alpha'])\n",
        "\n",
        "    # Log the best model with MLflow, passing the algo_name as \"MultinomialNB\"\n",
        "    log_mlflow(\"MultinomialNB\", best_model, X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Run the experiment for Multinomial Naive Bayes\n",
        "run_optuna_experiment()"
      ],
      "metadata": {
        "id": "4yJBwTxwPI2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 6: Optuna objective function for Random Forest\n",
        "def objective_rf(trial):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 300)  # Number of trees in the forest\n",
        "    max_depth = trial.suggest_int('max_depth', 3, 20)  # Maximum depth of the tree\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)  # Minimum samples required to split a node\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)  # Minimum samples required at a leaf node\n",
        "\n",
        "    # RandomForestClassifier setup\n",
        "    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth,\n",
        "                                   min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf,\n",
        "                                   random_state=42)\n",
        "    return accuracy_score(y_test, model.fit(X_train, y_train).predict(X_test))\n",
        "\n",
        "\n",
        "# Step 7: Run Optuna for Random Forest, log the best model only\n",
        "def run_optuna_experiment():\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective_rf, n_trials=30)\n",
        "\n",
        "    # Get the best parameters and log only the best model\n",
        "    best_params = study.best_params\n",
        "    best_model = RandomForestClassifier(n_estimators=best_params['n_estimators'],\n",
        "                                        max_depth=best_params['max_depth'],\n",
        "                                        min_samples_split=best_params['min_samples_split'],\n",
        "                                        min_samples_leaf=best_params['min_samples_leaf'],\n",
        "                                        random_state=42)\n",
        "\n",
        "    # Log the best model with MLflow, passing the algo_name as \"RandomForest\"\n",
        "    log_mlflow(\"RandomForest\", best_model, X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Run the experiment for Random Forest\n",
        "run_optuna_experiment()"
      ],
      "metadata": {
        "id": "d5htHL0ZPf_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set or create an experiment\n",
        "mlflow.set_experiment(\"LightGBM HP Tuning\")"
      ],
      "metadata": {
        "id": "axNMjYZpPs8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Remap the class labels from [-1, 0, 1] to [2, 0, 1]\n",
        "df['category'] = df['category'].map({-1: 2, 0: 0, 1: 1})\n",
        "\n",
        "# Step 2: Remove rows where the target labels (category) are NaN\n",
        "df = df.dropna(subset=['category'])\n",
        "\n",
        "# Step 3: TF-IDF vectorizer setup\n",
        "ngram_range = (1, 3)  # Trigram\n",
        "max_features = 1000  # Set max_features to 1000\n",
        "vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
        "X = vectorizer.fit_transform(df['clean_comment'])\n",
        "y = df['category']\n",
        "\n",
        "# Step 4: Apply SMOTE to handle class imbalance\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)"
      ],
      "metadata": {
        "id": "cNIRWmOFPtsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)"
      ],
      "metadata": {
        "id": "yS7hhANZP2JZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to log results in MLflow\n",
        "def log_mlflow(model_name, model, X_train, X_test, y_train, y_test, params, trial_number):\n",
        "    with mlflow.start_run():\n",
        "        # Log model type and trial number\n",
        "        mlflow.set_tag(\"mlflow.runName\", f\"Trial_{trial_number}_{model_name}_SMOTE_TFIDF_Trigrams\")\n",
        "        mlflow.set_tag(\"experiment_type\", \"algorithm_comparison\")\n",
        "\n",
        "        # Log algorithm name as a parameter\n",
        "        mlflow.log_param(\"algo_name\", model_name)\n",
        "\n",
        "        # Log hyperparameters\n",
        "        for key, value in params.items():\n",
        "            mlflow.log_param(key, value)\n",
        "\n",
        "        # Train model\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Log accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "        # Log classification report\n",
        "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
        "        for label, metrics in classification_rep.items():\n",
        "            if isinstance(metrics, dict):\n",
        "                for metric, value in metrics.items():\n",
        "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
        "\n",
        "        # Log the model\n",
        "        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n",
        "\n",
        "        return accuracy\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KYEi6wLeP5RI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Optuna objective function for LightGBM\n",
        "def objective_lightgbm(trial):\n",
        "    # Hyperparameter space to explore\n",
        "    n_estimators = trial.suggest_int('n_estimators', 100, 1000)\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
        "    max_depth = trial.suggest_int('max_depth', 3, 15)\n",
        "    num_leaves = trial.suggest_int('num_leaves', 20, 150)\n",
        "    min_child_samples = trial.suggest_int('min_child_samples', 10, 100)\n",
        "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 1.0)\n",
        "    subsample = trial.suggest_float('subsample', 0.5, 1.0)\n",
        "    reg_alpha = trial.suggest_float('reg_alpha', 1e-4, 10.0, log=True)  # L1 regularization\n",
        "    reg_lambda = trial.suggest_float('reg_lambda', 1e-4, 10.0, log=True)  # L2 regularization\n",
        "\n",
        "    # Log trial parameters\n",
        "    params = {\n",
        "        'n_estimators': n_estimators,\n",
        "        'learning_rate': learning_rate,\n",
        "        'max_depth': max_depth,\n",
        "        'num_leaves': num_leaves,\n",
        "        'min_child_samples': min_child_samples,\n",
        "        'colsample_bytree': colsample_bytree,\n",
        "        'subsample': subsample,\n",
        "        'reg_alpha': reg_alpha,\n",
        "        'reg_lambda': reg_lambda\n",
        "    }\n",
        "\n",
        "    # Create LightGBM model\n",
        "    model = LGBMClassifier(n_estimators=n_estimators,\n",
        "                           learning_rate=learning_rate,\n",
        "                           max_depth=max_depth,\n",
        "                           num_leaves=num_leaves,\n",
        "                           min_child_samples=min_child_samples,\n",
        "                           colsample_bytree=colsample_bytree,\n",
        "                           subsample=subsample,\n",
        "                           reg_alpha=reg_alpha,\n",
        "                           reg_lambda=reg_lambda,\n",
        "                           random_state=42)\n",
        "\n",
        "    # Log each trial as a separate run in MLflow\n",
        "    accuracy = log_mlflow(\"LightGBM\", model, X_train, X_test, y_train, y_test, params, trial.number)\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MgzGyL-oP7RZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Run Optuna for LightGBM, log the best model, and plot the importance of each parameter\n",
        "def run_optuna_experiment():\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective_lightgbm, n_trials=100)  # Increased to 100 trials\n",
        "\n",
        "    # Get the best parameters\n",
        "    best_params = study.best_params\n",
        "    best_model = LGBMClassifier(n_estimators=best_params['n_estimators'],\n",
        "                                learning_rate=best_params['learning_rate'],\n",
        "                                max_depth=best_params['max_depth'],\n",
        "                                num_leaves=best_params['num_leaves'],\n",
        "                                min_child_samples=best_params['min_child_samples'],\n",
        "                                colsample_bytree=best_params['colsample_bytree'],\n",
        "                                subsample=best_params['subsample'],\n",
        "                                reg_alpha=best_params['reg_alpha'],\n",
        "                                reg_lambda=best_params['reg_lambda'],\n",
        "                                random_state=42)\n",
        "\n",
        "    # Log the best model with MLflow and print the classification report\n",
        "    log_mlflow(\"LightGBM\", best_model, X_train, X_test, y_train, y_test, best_params, \"Best\")\n",
        "\n",
        "    # Plot parameter importance\n",
        "    optuna.visualization.plot_param_importances(study).show()\n",
        "\n",
        "    # Plot optimization history\n",
        "    optuna.visualization.plot_optimization_history(study).show()"
      ],
      "metadata": {
        "id": "--UFIdyFP-XY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the experiment for LightGBM\n",
        "run_optuna_experiment()"
      ],
      "metadata": {
        "id": "78eOjkpMQAS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model"
      ],
      "metadata": {
        "id": "7s0JDG1YQFF0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}